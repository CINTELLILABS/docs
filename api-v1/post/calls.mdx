---
title: "Send Call"
api: "POST https://api.bland.ai/v1/calls"
description: "Send an AI phone call with a custom objective and actions."
---

## Overview

Send an AI phone call with a custom objective and actions. This endpoint can be used to create dynamic phone calls where the AI agent can follow instructions, use tools, and follow a conversation pathway.

---

## Headers

<ParamField header="authorization" type="string" required>
  Your API key for authentication.
</ParamField>

<ParamField header="encrypted_key" type="string">
  A special key for using a BYOT (Bring Your Own Twilio) account. Only required for sending calls from your own Twilio account.
  
  Learn more about BYOT [here](/tutorials/custom-twilio).
</ParamField>

---

## Body Parameters

### Basic Parameters

<ParamField body="phone_number" type="string" required>
  The phone number to call. Must be a valid phone number in [E.164](https://en.wikipedia.org/wiki/E.164) format.
</ParamField>

<ParamField body="voice" type="string">
  The voice of the AI agent to use. Accepts any form of voice ID, including custom voice clones and voice presets.

  Default voices can be referenced directly by their name instead of an id.

  Usage example: voice: "maya"

  Bland Curated voices:

  - Josh
  - Florian
  - Derek
  - June
  - Nat
  - Paige
</ParamField>

<ParamField body="pathway_id" type="string">
  This is the pathway ID for the pathway you have created on our dev portal. You
  can access the ID of your pathways by clicking the 'Copy ID' button of your
  pathway [here](https://app.bland.ai/home?page=convo-pathways)

  Note: Certain parameters do not apply when using pathways.

  Example Simple Request body:

  ```json
  {
    "phone_number": "+1975934749",
    "pathway_id": "a0f0d4ed-f5f5-4f16-b3f9-22166594d7a7"
  }
  ```
</ParamField>

<ParamField body="pathway_version" type="integer">
  The version number of the pathway to use for the call. Defaults to the production version.
</ParamField>

<ParamField body="task" type="string" required>
  Note: Do not specify if using a pathway.

  Provide instructions, relevant information, and examples of the ideal conversation flow.

  This is your prompt where you are telling the agent what to do.

  Recommendations:

  - Include context and a background/persona for the agent like `"You are {name}, a customer service agent at {company} calling {name} about {reason}`.
  - Phrase instructions like you are speaking to the agent before the call.
  - Any time you tell the agent not to do something, provide an example of what they should do instead.
  - Keep the prompt under 2,000 characters where possible.
</ParamField>

<ParamField body="first_sentence" type="string">
  Makes your agent say a specific phrase or sentence for it's first response.
</ParamField>

<ParamField body="persona_id" type="string">
  The ID of the persona to use for the call.

  Personas act as pre-configured templates that automatically apply a configuration when you pass a persona_id to an outbound call. Think of them as "call presets" that you can reuse across multiple calls. 

  When using a persona_id, any parameters specified in your request body will override the corresponding parameters from the persona's configuration.

  You can access your persona IDs by clicking the "Personas" button at the bottom of the Send Call page, and then "Use and Manage".
</ParamField>

### Model Parameters

<ParamField body="model" default="base" type="string">
  Select a model to use for your call.

  Options: `base` or `turbo`.

  In nearly all cases, `base` is the best choice.

  <Accordion title="Model Differences">
    There are two different ways to use Bland:

    - `model: base`
      - The original, follows scripts/procedures most effectively.
      - Supports all features and capabilities.
      - Best for Custom Tools
    - `model: turbo`
      - The absolute fastest latency possible, can be verbose at times
      - Limited capabilities currently (excludes Transferring, IVR navigation, Custom Tools)
      - Extremely realistic conversation capabilities
  </Accordion>
</ParamField>

<ParamField body="language" default="en-US" type="string">
  Select a supported language of your choice.
  Optimizes every part of our API for that language - transcription, speech, and other inner workings.

  <Accordion title="Expand to view language options">
    The available language options are as follows:

    - `babel` - Babel (All Languages) - Experimental<sup>1</sup>
    - `en` - English
    - `babel-en` - English (Babel)
    - `en-US` - English (US)
    - `en-GB` - English (UK)
    - `en-AU` - English (Australia)
    - `en-NZ` - English (New Zealand)
    - `en-IN` - English (India)
    - `es` - Spanish
    - `babel-es` - Spanish (Babel)
    - `es-419` - Spanish (Latin America)
    - `fr` - French
    - `babel-fr` - French (Babel)
    - `fr-CA` - French (Canada)
    - `de` - German
    - `babel-de` - German (Babel)
    - `el` - Greek
    - `hi` - Hindi
    - `hi-Latn` - Hindi (Latin script)
    - `hu` - Hungarian
    - `ja` - Japanese
    - `ko` - Korean
    - `ko-KR` - Korean (Korea)
    - `vi` - Vietnamese
    - `pt` - Portuguese
    - `pt-BR` - Portuguese (Brazil)
    - `pt-PT` - Portuguese (Portugal)
    - `zh` - Chinese (Mandarin, Simplified)
    - `zh-CN` - Chinese (Mandarin, Simplified, China)
    - `zh-Hans` - Chinese (Mandarin, Simplified, Hans)
    - `zh-TW` - Chinese (Mandarin, Traditional)
    - `zh-Hant` - Chinese (Mandarin, Traditional, Hant)
    - `it` - Italian
    - `nl` - Dutch
    - `pl` - Polish
    - `ru` - Russian
    - `sv` - Swedish
    - `sv-SE` - Swedish (Sweden)
    - `da` - Danish
    - `da-DK` - Danish (Denmark)
    - `fi` - Finnish
    - `no` - Norwegian
    - `id` - Indonesian
    - `ms` - Malay
    - `tr` - Turkish
    - `uk` - Ukrainian
    - `bg` - Bulgarian
    - `cs` - Czech
    - `ro` - Romanian
    - `sk` - Slovak
    - `auto` - Auto Detect (English & Spanish)

    <sup>1</sup> The Bland Babel Transcription Engine (BETA) is our new proprietary transcription engine! Babel can handle multilingual conversations by identifying and switching languages on the fly. It's now in beta and available under the "babel" language mode.
    **Note: For pathway calls and prompts, make sure to prompt your agent to respond in the language they are spoken to.**
  </Accordion>
</ParamField>

<ParamField body="wait_for_greeting" default="false" type="boolean">
  By default, the agent starts talking as soon as the call connects.

  When wait_for_greeting is set to true, the agent will wait for the call recipient to speak first before responding.
</ParamField>

<ParamField body="pronunciation_guide" type="array" description="An array of objects where each object specifies a word and its pronunciation. Additional attributes can be added as needed.">
  The pronunciation guide is an `array` of `objects` that guides the agent on how to say specific words. Use this to improve clarity for acronyms, names, brand terms, or jargon.

  ```json
    [
      {
        "word": "example",
        "pronunciation": "ex-am-ple",
        "case_sensitive": "false",
        "spaced": "false"
    },
    {
      "word": "API",
      "pronunciation": "A P I",
      "case_sensitive": "true",
      "spaced": "true"
    }
  ]
  ```

  <Accordion title="Object Parameters">
    - `word`
      — the word you want to guide the LLM on how to pronounce
    - `pronunciation`
      — how the AI should pronounce the word, using syllables or space-separated characters. For example, `"A P I"` ensures each letter is spoken clearly rather than read as a word.
    - `case_sensitive`
      — whether or not to consider case. Particularly useful with names. EG: 'Max' the name versus 'max' the word. Defaults to false. `Not required`.
    - `spaced` 
      — whether to match whole words only. When true, "high" will match "high" but not "hightop". When false, it will match any word that contains "high". Defaults to true. `Not required`.
  </Accordion>
</ParamField>

<ParamField body="temperature" default={0.7} type="float">
  A value between 0 and 1 that controls the randomness of the LLM. 0 will cause more deterministic outputs while 1 will cause more random.

  Example Values: "0.9", "0.3", "0.5"
</ParamField>

<ParamField body="interruption_threshold" default="100" type="number">
  Adjusts how patient the AI is when waiting for the user to finish speaking.

  Lower values mean the AI will respond more quickly, while higher values mean the AI will wait longer before responding.

  Recommended range: 50-200
  •	50: Extremely quick, back and forth conversation
  •	100: Balanced to respond at a natural pace
  •	200: Very patient, allows for long pauses and interruptions. Ideal for collecting detailed information.

  Try to start with 100 and make small adjustments in increments of ~10 as needed for your use case.
</ParamField>

### Dispatch Parameters

<ParamField body="from" type="string">
  Specify a phone number to call from that you own or have uploaded from your Twilio account. Country code is required, spaces or parentheses must be excluded.

  By default, calls are initiated from a separate pool of numbers owned by Bland. If you are using your own twilio numbers, you must specify a matching encrypted_key in the create call request headers.
</ParamField>

<ParamField body="dialing_strategy" type="object" optional="true">
  Controls how the caller number (`from`) is selected when placing an outbound call.

  Use this field to influence how the system chooses a number that appears local or relevant to the callee, improving pickup rates. There are two supported strategies:

  #### 1. `local`

  Automatically selects a `from` number that matches the callee's area code for **US-based calls**. You must have purchased a local dialing add-on in the [add-ons section](https://app.bland.ai/dashboard/add-ons).

  Example:
  ```json
  {
    "dialing_strategy": { "type": "local" }
  }
  ```

  #### 2. `custom_pool`
  Selects a number from your own pre-configured pool of phone numbers. Designed for organizations that want full control over the caller IDs being used. 

  This is an enterprise only feature, to use this feature contact your Bland representative or reach out to sales.

  Example:
  ```json
  {
    "dialing_strategy": {
      "type": "custom_pool",
      "pool_id": "bd039087-decb-435a-a6e3-ca1ffbf89974"
    }
  }
  ```

  By default, Bland will choose a US-based number from our own pool of numbers.
</ParamField>

<ParamField body="timezone" default="America/Los_Angeles" type="string">
  Set the timezone for the call. Handled automatically for calls in the US.

  This helps significantly with use cases that rely on appointment setting, scheduling, or behaving differently based on the time of day.

  Timezone options are here in the TZ identifier column.
</ParamField>

<ParamField body="start_time" type="string">
  The time you want the call to start. If you don't specify a time (or the time is in the past), the call will send immediately.

  Set your time in the format YYYY-MM-DD HH:MM:SS -HH:MM (ex. 2021-01-01 12:00:00 -05:00).

  The timezone is optional, and defaults to UTC if not specified.

  Note: Scheduled calls can be cancelled with the POST /v1/calls/:call_id/stop endpoint.
</ParamField>

<ParamField body="transfer_phone_number" type="string">
  A phone number that the agent can transfer to under specific conditions - such as being asked to speak to a human or supervisor. This option will be ignored for pathways.

  <Accordion title="Prompting Notes">
    For best results:

    - Specify conditions that the agent should transfer to a human under (examples are great!)
    - In the `task`, refer to the action solely as "transfer" or "transferring".
    - Alternate phrasing such as "swap" or "switch" can mislead the agent, causing the action to be ignored.
  </Accordion>
</ParamField>

<ParamField body="transfer_list" type="object">
  Give your agent the ability to transfer calls to a set of phone numbers. This option will be ignored for pathways.

  Overrides transfer_phone_number if a transfer_list.default is specified.

  Will default to transfer_list.default, or the chosen phone number.

  Example usage to route calls to different departments:

  ```json
  {
    "transfer_list": {
        "default": "+12223334444",
        "sales": "+12223334444",
        "support": "+12223334444",
        "billing": "+12223334444"
    }
  }
  ```
</ParamField>

<ParamField body="max_duration" default="30" type="integer">
  When the call starts, a timer is set for the `max_duration` minutes. At the end of that timer, if the call is still active it will be automatically ended.

  Example Values: 20, 2
</ParamField>

### Knowledge Parameters

<ParamField body="tools" type="array">
  Add custom tools and knowledge bases to your call for your agent to call upon.

  Example:
  ```json
  {
    "tools": [
      "TL-ba6c4237-67c2-40e8-868b-60d429a84eda",
      "KB-30d465c0-22d0-41e0-a63d-61bcacc277e7"
    ]
  }
  ```

  Read more about custom tools [here](https://docs.bland.ai/tutorials/custom-tools#custom-tools)
</ParamField>

### Audio Parameters

<ParamField body="background_track" type="string">
  Select an audio track that you'd like to play in the background during the call. The audio will play continuously when the agent isn't speaking, and is incorporated into it's speech as well.

  Use this to provide a more natural, seamless, engaging experience for the conversation. We've found this creates a significantly smoother call experience by minimizing the stark differences between total silence and the agent's speech.

  Options:

  - null - Default, will play audible but quiet phone static.
  - office - Office-style soundscape. Includes faint typing, chatter, clicks, and other office sounds.
  - cafe - Cafe-like soundscape. Includes faint talking, clinking, and other cafe sounds.
  - restaurant - Similar to cafe, but more subtle.
  - none - Minimizes background noise
</ParamField>

<ParamField body="noise_cancellation" default="false" type="boolean">
  Toggles noise filtering or suppression in the audio stream to filter out background noise.
</ParamField>

<ParamField body="block_interruptions" default="false" type="boolean">
  When set to `true`, the AI will not respond or process interruptions from the user.
</ParamField>

<ParamField body="record" default="false" type="boolean">
  To record your phone call, set `record` to true. When your call completes, you can access through the `recording_url` field in the call details or your webhook.
</ParamField>

### Voicemail Parameters

<ParamField body="voicemail" type="object">
  Configuration for handling voicemails during outbound calls. This object controls how the AI behaves when it encounters a voicemail, including whether to leave a message, send an SMS notification, or detect voicemails more intelligently using AI.

  It has the following parameters:

  - `message` (string): The message the AI will leave if a voicemail is detected. This message will be played after the beep, then the call will end. This field is required if `action` is set to `leave_message`.

  <br />

  - `action` (enum): What the AI should do when it detects a voicemail. The default is `"hangup"`. Available options:
    - `"hangup"`: Immediately end the call without leaving a message.
    - `"leave_message"`: Play the `message` and then end the call.
    - `"ignore"`: Continue the call as if no voicemail was detected (used for IVRs or special routing).

  <br />

  - `sms` (object): Optional. Configuration for sending an SMS notification when a voicemail is left. Contains:
    - `to` (string): The phone number to send the SMS to (usually the same as the original callee).
    - `from` (string): The phone number to send the SMS from (must be a number you own and have SMS permissions for).
    - `message` (string): The body of the SMS message. Keep concise and clear.

  <br />

  - `sensitive` (boolean): When `true`, uses LLM-based analysis to detect frequent voicemails. The default is `false`.

  Example:

  ```json
  {
    "voicemail": {
      "message": "Hi, just calling to follow up. Please call us back when you can.",
      "action": "leave_message",
      "sms": {
        "to": "+18005550123",
        "from": "+18005550678",
        "message": "We just left you a voicemail. Call us back anytime!"
      },
      "sensitive": true
    }
  }
  ```
</ParamField>

### Analysis Parameters

<ParamField body="citation_schema_ids" type="string[]">
  The citation schema is an incredibly powerful tool for running **_post call analysis_**, including specific variable extractions, conditional logic, and more.

  You can build a citation schema [here](https://app.bland.ai/dashboard/analytics?tab=citations).

  After building the citation schema (or schemas), you can copy their UUIDs and reference them in your API request for outgoing calls (and you can also attach them to your inbound phone numbers).

  Here's an example:

  ```json
  {
    "citation_schema_ids": ["dcad76eb-57b6-4be6-922f-8a5a95e2ffrt"]
  }
  ```

  > Note: Citation schemas are very powerful and accurate, but also are more resource intensive to run. As such, for the time being, they are an enterprise-only feature.

</ParamField>

### Post Call Parameters

<ParamField body="summary_prompt" type="string">
  (Optional) Custom instructions for how the call summary should be generated after the call completes. Use this to provide specific guidance or context for the AI when writing the post-call summary. Maximum length: 2000 characters.

  Example:
  ```json
  {
    "summary_prompt": "Summarize the call in 2-3 sentences, focusing on the customer's main concern and any next steps discussed."
  }
  ```
</ParamField>

<ParamField body="retry" type="object">
  If the call goes to voicemail, you can set up the call to retry, after a configurable delay. You can also update the voicemail_action, and voicemail_message in the retry object, for the re-tried call.

  Takes in the following parameters:

  - `wait` (integer): The delay in seconds before the call is retried.
  - `voicemail_action` (enum): The action to take when the call goes to voicemail. Options: `hangup`, `leave_message`, `ignore`.
  - `voicemail_message` (string): The message to leave when the call goes to voicemail.

  Example:

  ```json
  {
      "retry": {
          "wait": 10,
          "voicemail_action": "leave_message",
          "voicemail_message": "Hello, this is a test message."
      }
  }
  ```
</ParamField>

<ParamField body="dispositions" type="string[]">
A list of possible outcome tags (dispositions) you define. After the call ends, the AI reviews the transcript and picks **one** of these tags to describe how the call went.

Tag selection is based **only** on the transcript, no metadata or external inputs are used.

The chosen tag will appear in the `disposition_tag` field of the call data.

  <Accordion title="Built-in Disposition Tags">
    If no custom `dispositions` are provided, the AI will automatically select from these built-in tags:
    
    - `INTERESTED` - Customer shows clear interest in the offering
    - `NOT_INTERESTED` - Customer expresses lack of interest
    - `FOLLOW_UP_REQUIRED` - Customer needs additional follow-up
    - `CALL_BACK_SCHEDULED` - A callback appointment was scheduled
    - `TRANSFERRED` - Call was transferred to another agent/department
    - `OBJECTION_RAISED` - Customer raised concerns or objections
    - `NEEDS_MORE_INFO` - Customer requires additional information
    - `NOT_QUALIFIED` - Customer does not meet qualification criteria
    - `NO_CONTACT_MADE` - Unable to establish meaningful contact
    - `COMPLETED_ACTION` - Customer completed the desired action
    - `DO_NOT_CONTACT` - Customer requested no future contact
    - `AGENT_ENDED_CALL` - Call ended by AI (auto-assigned for calls >2 minutes without transcript)
    - `NO_ANSWER` - Call was not answered (auto-assigned by system)
    - `BUSY` - Number was busy (auto-assigned by system)
    - `CANCELED` - Call was canceled (auto-assigned by system)
    - `FAILED` - Call failed to connect (auto-assigned by system)
  </Accordion>

  Example:

  ```json
    {
      "dispositions": ["got_full_name_and_number", "no_information_provided", "transferred_to_agent"]
    }
  ```
</ParamField>

### Advanced Parameters

<ParamField body="request_data" type="object">
  Custom key-value data you send with the call. This information is available as variables inside your prompt, pathway, or tools — but only if the call is answered.

```json
  {
    "task": "Say hello to the user, who's name is {{name}}",
    "request_data": {
      "name": "John Doe"
    }
  }
```

In this case, the AI would say: "Hello, John".

</ParamField>

<ParamField body="metadata" type="object">
  Add any additional information you want to associate with the call. This data is accessible for all calls, regardless of if they are picked up or not. This can be used to track calls or add custom data to the call.

  Anything that you put here will be returned in the post call webhook under metadata.

  Example:

  ```json
  {
    "metadata": {
      "campaign_id": "1234",
      "source": "web"
    }
  }
  ```

</ParamField>

<ParamField body="webhook" type="string">
  When the call ends, call information is sent to this webhook URL.
</ParamField>

<ParamField body="webhook_events" type="string[]">
  Specify which events you want to stream to the webhook, during the call.

  Options:

  - `queue`
  - `call`
  - `latency`
  - `webhook`
  - `tool`
  - `dynamic_data`
  - `citations` (Sent separately, Enterprise only)

Example payloads:
  <CodeGroup>

```json queue
// ex 1
{
  "message": "Call enqueued",
  "call_id": "12345678-1234-1234-1234-123456789abc",
  "category": "queue",
  "log_level": "info"
}
```

```json call
// ex 1
{
  "message": "Call connected",
  "call_id": "12345678-1234-1234-1234-123456789abc",
  "category": "call",
  "log_level": "info"
}
// ex 2
{
  "message": "Sending first sentence: Hello, thank you for reaching out. I'd like to get to know you a bit better. How are you feeling today?",
  "call_id": "12345678-1234-1234-1234-123456789abc",
  "category": "call",
  "log_level": "info"
}
// ex 3
{
  "message": "Agent speech: Hello, thank you for reaching out.",
  "call_id": "12345678-1234-1234-1234-123456789abc",
  "category": "call",
  "log_level": "info"
}
// ex 4
{
  "message": "Handling user speech: Yeah. I'm thirty six. And I'm five foot nine.",
  "call_id": "12345678-1234-1234-1234-123456789abc",
  "category": "call",
  "log_level": "info"
}
// ex 5
{
  "message": "Webhook Response: 200  | Webhook Response Data: [object Object] | Response Time: 689ms",
  "call_id": "87654321-4321-4321-4321-cba987654321",
  "category": "call",
  "log_level": "info"
}
```

```json latency
// ex 1
{
  "message": "TTS: 218ms",
  "call_id": "12345678-1234-1234-1234-123456789abc",
  "category": "latency",
  "log_level": "performance"
}
// ex 2
{
  "message": "LLM: 266ms",
  "call_id": "12345678-1234-1234-1234-123456789abc",
  "category": "latency",
  "log_level": "performance"
}
```

```json webhook
{
  "message": "Storing dynamic data messages: \n\n answer : \"true\"",
  "call_id": "87654321-4321-4321-4321-cba987654321",
  "category": "call",
  "log_level": "info"
}
```

```json tool
{
  "message": "Executing custom tool: Test Tool 4 with input: [object Object]",
  "call_id": "abcdef12-3456-7890-abcd-ef1234567890",
  "category": "call",
  "log_level": "info"
}
```

```json dynamic_data
{
  "message": "Storing dynamic data: \n\n vector_data : {\"data\":{\"results\":[{\"id\":\"fedcba98-7654-3210-fedc-ba9876543210\",\"input_text\":\"Here are details on the restaurant...\",\"similarity\":0.103339002763233,\"chunk_index\":0}]},\"errors\":null}",
  "call_id": "abcdef12-3456-7890-abcd-ef1234567890",
  "category": "call",
  "log_level": "info"
}
```

```json citations
{
  "call_id": "12345678-1234-1234-1234-123456789abc",
  "user_id": "11111111-2222-3333-4444-555555555555",
  "event_type": "citations",
  "timestamp": "2025-07-03T16:41:15.231Z",
  "citations": [
    {
      "call_id": "12345678-1234-1234-1234-123456789abc",
      "variable_name": "User height",
      "variable_type": "boolean",
      "value": true,
      "cited_utterances": [
        {
          "id": "aaaaaaaa-bbbb-cccc-dddd-eeeeeeeeeeee",
          "idx": 3,
          "start_time": 24.096,
          "end_time": 27.424,
          "confidence": 0.17166666666666666,
          "channel": 1,
          "transcript": "I am 36 and I am 5'9\".",
          "speaker_id": "SPEAKER_1_0",
          "speaker_name": null,
          "speaker_description": null,
          "topics": [
            "customer_information_provided"
          ],
          "topics_meta": "{\"customer_information_provided\":\"customer providing personal details\"}",
          "utterance_type": "answer"
        }
      ],
      "schema_id": "99999999-8888-7777-6666-555555555555"
    },
    {
      "call_id": "12345678-1234-1234-1234-123456789abc",
      "variable_name": "Caller Age",
      "variable_type": "number",
      "value": 36,
      "cited_utterances": [
        {
          "id": "aaaaaaaa-bbbb-cccc-dddd-eeeeeeeeeeee",
          "idx": 3,
          "start_time": 24.096,
          "end_time": 27.424,
          "confidence": 0.17166666666666666,
          "channel": 1,
          "transcript": "I am 36 and I am 5'9\".",
          "speaker_id": "SPEAKER_1_0",
          "speaker_name": null,
          "speaker_description": null,
          "topics": [
            "customer_information_provided"
          ],
          "topics_meta": "{\"customer_information_provided\":\"customer providing personal details\"}",
          "utterance_type": "answer"
        },
        {
          "id": "bbbbbbbb-cccc-dddd-eeee-ffffffffffff",
          "idx": 4,
          "start_time": 30.56,
          "end_time": 35.455,
          "confidence": 0.5672727272727273,
          "channel": 0,
          "transcript": "All right. So you're 36 years old and five foot nine. That's great. How's your day been so far? Anything exciting happened?",
          "speaker_id": "SPEAKER_0_0",
          "speaker_name": null,
          "speaker_description": null,
          "topics": [
            "day_review_inquiry"
          ],
          "topics_meta": "{\"day_review_inquiry\":\"agent inquiring about the customer's day and any exciting events\"}",
          "utterance_type": "question"
        }
      ],
      "schema_id": "99999999-8888-7777-6666-555555555555"
    },
    {
      "call_id": "12345678-1234-1234-1234-123456789abc",
      "variable_name": "Caller feeling",
      "variable_type": "string",
      "value": null,
      "cited_utterances": [],
      "schema_id": "99999999-8888-7777-6666-555555555555"
    }
  ]
}
```

</CodeGroup>

</ParamField>

<ParamField body="dynamic_data" type="object[]">
  Integrate data from external APIs into your agent's knowledge.

  Set to `null` or an empty string to clear dynamic data settings.

  ```json
    "dynamic_data": [
      {
        "url": "endpoint",
        "method": "GET",
        "body": [],
        "headers": [
          {
            "key": "Content-Type",
            "value": "application/json"
          }
        ],
        "query": [],
        "cache": true,
        "response_data": [
          {
            "context": "",
            "data": "$",
            "name": ""
          }
        ]
      }
    ],
  ```
</ParamField>

<ParamField body="keywords" default="[]" type="string[]">
  These words will be boosted in the transcription engine - recommended for proper nouns or words that are frequently mis-transcribed.

  For example, if the word Blandy is frequently transcribed as a homonym like "Reese" you could do this:

  ```json
    {
      "keywords": ["Blandy"]
    }
  ```

  For stronger keyword boosts, you can place a colon then a boost factor after the word. The default boost factor is 2.

  ```json
    {
      "keywords": ["Blandy:3"]
    }
  ```
</ParamField>

<ParamField body="ignore_button_press" type="boolean" default="false">
  When `true`, the system will ignore DTMF input (Dual-Tone Multi-Frequency) — the tones generated when a user presses keys on their phone keypad (e.g., 0-9, *, #).  
  This disables any in-call actions triggered by keypad input, such as menu navigation or transfers.  
  Useful when your agent should handle the entire call conversationally, without responding to button presses.
</ParamField>

<ParamField body="precall_dtmf_sequence" type="string">
  A sequence of DTMF digits that will be played before the call starts. Acceptable characters are 0-9, \*, #, and w, where w is a pause of 0.5 seconds.
  Example:

  ```json
    {
      "precall_dtmf_sequence": "1234567890*#w"
    }
  ```
</ParamField>

## Response

<ResponseField name="status" type="string">
  Can be `success` or `error`.
</ResponseField>

<ResponseField name="message" type="string">
  A message explaining the status of the call.
</ResponseField>

<ResponseField name="call_id" type="string">
  A unique identifier for the call (present only if status is `success`).
</ResponseField>

<ResponseField name="batch_id" type="string">
  The batch ID of the call (present only if status is `success`).
</ResponseField>


<ResponseField name="errors" type="array">
  For validation errors, a detailed list of each field with an error and it's error message.

  Example:

  ```json
  {
      "status": "error",
      "message": "Invalid parameters",
      "errors": [
          "Missing required parameter: phone_number.",
          "Missing required parameter: task.",
          "Phone number must be a string or number.",
          "Task must be a string."
      ]
  }
  ```
</ResponseField>

<ResponseExample>

```json
{
  "status": "success",
  "message": "Call successfully queued.",
  "call_id": "9d404c1b-6a23-4426-953a-a52c392ff8f1",
  "batch_id": null
}
```

</ResponseExample>
