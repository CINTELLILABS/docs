---
title: "Send Call" 
api: "POST https://api.bland.ai/v1/calls"
description: "Send an AI phone call with a custom objective and actions."
---

## Overview

Send an AI phone call with a custom objective and actions. This endpoint can be used to create dynamic phone calls where the AI agent can follow instructions, use tools, and follow a conversation pathway.

---

## Headers

<ParamField header="authorization" type="string" required>
  Your API key for authentication.
</ParamField>

<ParamField header="encrypted_key" type="string">
  A special key for using a BYOT (Bring Your Own Twilio) account. Only required for sending calls from your own Twilio account.
</ParamField>

---

## Body Parameters
<ParamField body="phone_number" type="string" required>
  The phone number to call. Must be a valid phone number in [E.164](https://en.wikipedia.org/wiki/E.164) format. 
</ParamField>
<ParamField body="pathway_id" type="string">
  This is the pathway ID for the pathway you have created on our dev portal. You
  can access the ID of your pathways by clicking the 'Copy ID' button of your
  pathway [here](https://app.bland.ai/home?page=convo-pathways)

  Note: Certain parameters do not apply when using pathways.

  Example Simple Request body: 
```json
{
  "phone_number": "+1975934749",
  "pathway_id": "a0f0d4ed-f5f5-4f16-b3f9-22166594d7a7"
}
```
</ParamField>
<ParamField body="task" type="string" required>
  Note: Do not specify if using a pathway.

  Provide instructions, relevant information, and examples of the ideal conversation flow.

  This is your prompt where you are telling the agent what to do.

  Recommendations:
    - Include context and a background/persona for the agent like `"You are {name}, a customer service agent at {company} calling {name} about {reason}`.
    - Phrase instructions like you are speaking to the agent before the call.
    - Any time you tell the agent not to do something, provide an example of what they should do instead.
    - Keep the prompt under 2,000 characters where possible.
</ParamField>
<ParamField body="voice" type="string">
  The voice of the AI agent to use. Accepts any form of voice ID, including custom voice clones and voice presets.

  Default voices can be referenced directly by their name instead of an id.

  Usage example: voice: "maya"

  Bland Curated voices:
  - Josh
  - Florian
  - Derek
  - June
  - Nat
  - Paige
</ParamField>
<ParamField body="background_track" type="string">
Select an audio track that you'd like to play in the background during the call. The audio will play continuously when the agent isn't speaking, and is incorporated into it's speech as well.

Use this to provide a more natural, seamless, engaging experience for the conversation. We’ve found this creates a significantly smoother call experience by minimizing the stark differences between total silence and the agent’s speech.

Options:
	- null - Default, will play audible but quiet phone static.
	- office - Office-style soundscape. Includes faint typing, chatter, clicks, and other office sounds.
	- cafe - Cafe-like soundscape. Includes faint talking, clinking, and other cafe sounds.
	- restaurant - Similar to cafe, but more subtle.
	- none - Minimizes background noise
</ParamField>
<ParamField body="first_sentence" type="string">
  Makes your agent say a specific phrase or sentence for it's first response.
</ParamField>
<ParamField body="wait_for_greeting" type="boolean" default="false">
  By default, the agent starts talking as soon as the call connects. 

  When wait_for_greeting is set to true, the agent will wait for the call recipient to speak first before responding.
</ParamField>
<ParamField body="block_interruptions" type="boolean" default="false">
    When set to `true`, the AI will not respond or process interruptions from the user.
</ParamField>
<ParamField body="interruption_threshold" type="number" default="100">
  Adjusts how patient the AI is when waiting for the user to finish speaking.


Lower values mean the AI will respond more quickly, while higher values mean the AI will wait longer before responding.

Recommended range: 50-200
	•	50: Extremely quick, back and forth conversation
	•	100: Balanced to respond at a natural pace
	•	200: Very patient, allows for long pauses and interruptions. Ideal for collecting detailed information.

Try to start with 100 and make small adjustments in increments of ~10 as needed for your use case.

</ParamField>
<ParamField body="model" type="string" default="enhanced">
  Select a model to use for your call.


Options: base, turbo and enhanced.

In nearly all cases, enhanced is the best choice.

  <Accordion title="Model Differences">
	model: enhanced
	- Much faster latency and very conversational, works best with objective-based prompts.
	- Supports all features and capabilities.
  
	model: turbo
	- The absolute fastest latency possible, can be verbose at times
	- Limited capabilities currently (excludes Transferring, IVR navigation, Custom Tools)
	- Extremely realistic conversation capabilities

  </Accordion>
</ParamField>
<ParamField body="temperature" type="float" default={0.7}>
  A value between 0 and 1 that controls the randomness of the LLM. 0 will cause more deterministic outputs while 1 will cause more random.

  Example Values: "0.9", "0.3", "0.5"

</ParamField>
<ParamField body="keywords" type="string[]" default="[]">
  These words will be boosted in the transcription engine - recommended for proper nouns or words that are frequently mis-transcribed.


For example, if the word Blandy is frequently transcribed as a homonym like “Reese” you could do this:
```json
  {
    "keywords": ["Blandy"]
  }
  ```

For stronger keyword boosts, you can place a colon then a boost factor after the word. The default boost factor is 2.

```json
  {
    "keywords": ["Blandy:3"]
  }
  ```
</ParamField>
<ParamField body="pronunciation_guide" type="array" description="An array of objects where each object specifies a word and its pronunciation. Additional attributes can be added as needed.">
  The pronunciation guide is an `array` of `objects` that guides the agent on how to say specific words. This is great for situations with complicated terms or names. 


```json
  [
    {
      "word": "example",
      "pronunciation": "ex-am-ple",
      "case_sensitive": "false",
      "spaced": "false"
  },
  {
    "word": "API",
    "pronunciation": "A P I",
    "case_sensitive": "true",
    "spaced": "true"
  }
]
```

  <Accordion title="Object Parameters">
    - `word`
      — the word you want to guide the LLM on how to pronounce
    - `pronunciation`
      — the word you want to guide the LLM on how to pronounce.
    - `case_sensitive`
      — whether or not to consider case. Particularly useful with names. EG: 'Max' the name versus 'max' the word. Defaults to false. `Not required`.
    - `spaced` 
      — whether or not to consider spaces. When `true` the word 'high' would be flagged but NOT 'hightop'. Defaults to true. `Not required`.
  </Accordion>
</ParamField>
<ParamField body="transfer_phone_number" type="string">
  A phone number that the agent can transfer to under specific conditions - such as being asked to speak to a human or supervisor. This option will be ignored for pathways.


<Accordion title="Prompting Notes">
    For best results:
    - Specify conditions that the agent should transfer to a human under (examples are great!)
    - In the `task`, refer to the action solely as "transfer" or "transferring".
    - Alternate phrasing such as "swap" or "switch" can mislead the agent, causing the action to be ignored.
</Accordion>
</ParamField>
<ParamField body="transfer_list" type="object">
  Give your agent the ability to transfer calls to a set of phone numbers. This option will be ignored for pathways.


Overrides transfer_phone_number if a transfer_list.default is specified.

Will default to transfer_list.default, or the chosen phone number.

Example usage to route calls to different departments:

```json
{
  "transfer_list": {
      "default": "+12223334444",
      "sales": "+12223334444",
      "support": "+12223334444",
      "billing": "+12223334444"
  }
}
```

</ParamField>
<ParamField body="language" type="string" default="en-US">
  Select a supported language of your choice. 
  Optimizes every part of our API for that language - transcription, speech, and other inner workings.


  <Accordion title="Expand to view language options">
    The available language options are as follows:
    - `en` - English
    - `en-US` - English (US)
    - `en-GB` - English (UK)
    - `en-AU` - English (Australia)
    - `en-NZ` - English (New Zealand)
    - `en-IN` - English (India)
    - `zh` - Chinese (Mandarin, Simplified)
    - `zh-CN` - Chinese (Mandarin, Simplified, China)
    - `zh-Hans` - Chinese (Mandarin, Simplified, Hans)
    - `zh-TW` - Chinese (Mandarin, Traditional)
    - `zh-Hant` - Chinese (Mandarin, Traditional, Hant)
    - `es` - Spanish
    - `es-419` - Spanish (Latin America)
    - `fr` - French
    - `fr-CA` - French (Canada)
    - `de` - German
    - `el` - Greek
    - `hi` - Hindi
    - `hi-Latn` - Hindi (Latin script)
    - `ja` - Japanese
    - `ko` - Korean
    - `ko-KR` - Korean (Korea)
    - `pt` - Portuguese
    - `pt-BR` - Portuguese (Brazil)
    - `it` - Italian
    - `nl` - Dutch
    - `pl` - Polish
    - `ru` - Russian
    - `sv` - Swedish
    - `sv-SE` - Swedish (Sweden)
    - `da` - Danish
    - `da-DK` - Danish (Denmark)
    - `fi` - Finnish
    - `id` - Indonesian
    - `ms` - Malay
    - `tr` - Turkish
    - `uk` - Ukrainian
    - `bg` - Bulgarian
    - `cs` - Czech
    - `ro` - Romanian
    - `sk` - Slovak
  </Accordion>
</ParamField>
<ParamField body="pathway_version" type="integer">
  The version number of the pathway to use for the call. Defaults to the production version.
</ParamField>
<ParamField body="local_dialing" type="boolean" default="false">
  When `true`, automatically selects a "from" number that matches the callee's area code for US-based calls. Must have purchased a local dialing add-on in the [add-ons section](https://app.bland.ai/dashboard/add-ons).
</ParamField>
<ParamField body="voicemail_sms" type="boolean" default="false">
  When `true`, if a voicemail is left, an SMS is also sent to the callee (requires SMS configuration).
</ParamField>
<ParamField body="dispatch_hours" type="object">
  Restricts calls to certain hours in your timezone. Specify the timezone and time windows using 24-hour format.


Supported time formats:
	•	24-hour: “13:00”, “09:30”
	•	12-hour: “1:00pm”, “9:30am”
	•	Military: “1300”, “0930”

Example:

```json
{
  "start": "09:00",
  "end": "17:00"
}
```
The times will be automatically converted to UTC for processing. If the end time is before the start time (e.g. “22:00” to “06:00”), it will be interpreted as spanning overnight.
</ParamField>
<ParamField body="sensitive_voicemail_detection" type="boolean" default="false">
  When `true`, uses LLM-based analysis to detect frequent voicemails. 
</ParamField>
<ParamField body="noise_cancellation" type="boolean" default="false">
  Toggles noise filtering or suppression in the audio stream to filter out background noise.
</ParamField>
<ParamField body="ignore_button_press" type="boolean" default="false">
  When `true`, DTMF (digit) presses are ignored, disabling menu navigation or call transfers triggered by keypad input.
</ParamField>
<ParamField body="language_detection_period" type="integer">
  After this many seconds have passed, the language detection will run and change the AI's language configuration if it's different from the initial setting.


Shorter periods make the language switch faster, while longer periods are more accurate.

Valid range: 10-100 seconds.

The current language at a given moment can be accessed via the \{\{language\}\} prompt variable in Pathways.

</ParamField>
<ParamField body="language_detection_options" type="string[]">
  If `language_detection_period` is set, this array can be used to narrow down the languages that the AI can switch to.


By default, these select languages can be detected (and switched to) at any time during the call:

  <Accordion title="Expand to view language detection options">
    - `es` - Spanish
    - `en` - English
    - `hi` - Hindi
    - `ja` - Japanese
    - `ru` - Russian
    - `uk` - Ukrainian
    - `sv` - Swedish
    - `zh` - Chinese
    - `pt` - Portuguese
    - `nl` - Dutch
    - `tr` - Turkish
    - `fr` - French
    - `de` - German
    - `id` - Indonesian
    - `ko` - Korean
    - `it` - Italian
  </Accordion>

Any values passed into language_detection_options must be from that same list.

Note: The supported languages and their mappings at any given moment can be accessed through https://api.bland.ai/v1/languages.
</ParamField>
<ParamField body="timezone" type="string" default="America/Los_Angeles">
  Set the timezone for the call. Handled automatically for calls in the US.


This helps significantly with use cases that rely on appointment setting, scheduling, or behaving differently based on the time of day.

Timezone options are here in the TZ identifier column.

</ParamField>
<ParamField body="request_data" type="object">
  Request data fields are available to the AI agent during the call when referenced in the associated pathway or task. This data is accessible in variables if the call is answered.
  For example, let's say in your app you want to programmatically set the name of the person you're calling. You could set `request_data` to:
```json
  {
    "task": "Say hello to the user, who's name is {{name}}", // also works in the prompt, tools, etc.
    "request_data": {
      "name": "John Doe"
    }
  }
```
</ParamField>
<ParamField body="tools" type="array">
  Interact with the real world through API calls.


Detailed tutorial here: [Custom Tools](https://docs.bland.ai/tutorials/custom-tools#custom-tools)
</ParamField>
<ParamField body="start_time" type="string">
  The time you want the call to start. If you don't specify a time (or the time is in the past), the call will send immediately.


Set your time in the format YYYY-MM-DD HH:MM:SS -HH:MM (ex. 2021-01-01 12:00:00 -05:00).

The timezone is optional, and defaults to UTC if not specified.

Note: Scheduled calls can be cancelled with the POST /v1/calls/:call_id/stop endpoint.

</ParamField>
<ParamField body="voicemail_message" type="string">
  When the AI encounters a voicemail, it will leave this message after the beep and then immediately end the call.


Warning: If amd is set to true or voicemail_action is set to ignore, then this will still work for voicemails, but it will not hang up for IVR systems.

</ParamField>
<ParamField body="voicemail_action" type="enum" default="hangup">
  This is processed separately from the AI's decision making, and overrides it.


Options:
	•	hangup
	•	leave_message
	•	ignore

Examples:
	•	Call is answered by a voicemail (specifically with a beep or tone):
	•	If voicemail_message is set, that message will be left and then the call will end.
	•	Otherwise, the call immediately ends (regardless of amd)
	•	Call is answered by an IVR system or phone tree:
	•	If amd is set to true, the AI will navigate the system and continue as normal.
	•	If voicemail_action is set to ignore, the AI will ignore the IVR and continue as normal.
	•	Otherwise, if voicemail_message is set then it’ll leave that message and end the call.
	•	Finally, if none of those conditions are met, the call will end immediately.

Note: If voicemail_message is set, then the AI will leave the message regardless of the voicemail_action.
</ParamField>
<ParamField body="retry" type="object">
    If the call goes to voicemail, you can set up the call to retry, after a configurable delay. You can also update the voicemail_action, and voicemail_message in the retry object, for the re-tried call.


Takes in the following parameters:
- `wait` (integer): The delay in seconds before the call is retried.
- `voicemail_action` (enum): The action to take when the call goes to voicemail. Options: `hangup`, `leave_message`, `ignore`.
- `voicemail_message` (string): The message to leave when the call goes to voicemail.

Example:

```json
{
    "retry": {
        "wait": 10,
        "voicemail_action": "leave_message",
        "voicemail_message": "Hello, this is a test message."
    }
}
```
</ParamField>
<ParamField body="max_duration" type="integer" default="30">
  When the call starts, a timer is set for the `max_duration` minutes. At the end of that timer, if the call is still active it will be automatically ended.


Example Values: 20, 2
</ParamField>
<ParamField body="record" type="boolean" default="false">
  To record your phone call, set `record` to true. When your call completes, you can access through the `recording_url` field in the call details or your webhook.  
</ParamField>
<ParamField body="from" type="string">
  Specify a phone number to call from that you own or have uploaded from your Twilio account. Country code is required, spaces or parentheses must be excluded.


By default, calls are initiated from a separate pool of numbers owned by Bland. If you are using your own twilio numbers, you must specify a matching encryped_key in the create call request headers.
</ParamField>
<ParamField body="webhook" type="string">
  When the call ends, call information is sent to this webhook URL.


</ParamField>
<ParamField body="webhook_events" type="string[]">
    Specify which events you want to stream to the webhook, during the call.


Options:
- `queue`
- `call`
- `latency`
- `webhook`
- `tool`
- `dynamic_data`

Example Payload:

```json
  {
    "message": "LLM: 411ms",
    "call_id": "0fb3c518-e941-48fd-a32c-67d59c541336",
    "category": "latency",
    "log_level": "performance"
  }
  ```

</ParamField>
<ParamField body="metadata" type="object">
Add any additional information you want to associate with the call. This data is accessible for all calls, regardless of if they are picked up or not. This can be used to track calls or add custom data to the call.


Anything that you put here will be returned in the post call webhook under metadata.

Example:

```json
{
  "metadata": {
    "campaign_id": "1234",
    "source": "web"
  }
}
```
</ParamField>
<ParamField body="analysis_preset" type="string">
  The analysis preset UUID used to analyze the call, must be created on the [analysis presets page](https://app.bland.ai/dashboard/analytics?tab=analysis_presets). 


All fields in the preset configuration are filled at the end of the call by analyzing the transcript.

Example:

```json
  {
    "analysis_preset": "a0f0d4ed-f5f5-4f16-b3f9-22166594d7a7"
  }
  ```
</ParamField>
<ParamField body="available_tags" type="string[]">
 An array of disposition tags. Uopon call completion, the AI will evaluate the transcripts of the call and assign one of the tags to the "disposition_tag" field. Tags are assigned exclusively by looking at the transcript and no other information.

Example:

```json
  {
    "available_tags": ["got_full_name_and_number", "no_information_provided", "transferred_to_agent"]
  }
  ```
</ParamField>
<ResponseField name="status" type="string">
  Can be `success` or `error`.
</ResponseField>
<ResponseField name="call_id" type="string">
  A unique identifier for the call (present only if status is `success`).
</ResponseField>
<ResponseField name="batch_id" type="string">
  The batch ID of the call (present only if status is `success`).
</ResponseField>


<ResponseField name="message" type="string">
  A message explaining the status of the call.
</ResponseField>


<ResponseField name="errors" type="array">
  For validation errors, a detailed list of each field with an error and it's error message.


Example:

```json
{
    "status": "error",
    "message": "Invalid parameters",
    "errors": [
        "Missing required parameter: phone_number.",
        "Missing required parameter: task.",
        "Phone number must be a string or number.",
        "Task must be a string."
    ]
}
```

</ResponseField>

<ResponseExample>


```json
{
  "status": "success",
  "message": "Call successfully queued.",
  "call_id": "9d404c1b-6a23-4426-953a-a52c392ff8f1",
  "batch_id": null
}
```

</ResponseExample>
